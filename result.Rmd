---
---
---

# **P&S-2025: Lab assignment 3**

## **Oleksii Lasiichuk, Kyrylo Omelianchuk, Sofiia Sychak**

#### Work Breakdown Structure: - Task 1: --- Kyrylo - Task 2: --- Oleksii - Task 3: --- Sofiia

```{r}
# our team id number 
id <- 32
set.seed(id)

```

Part I: Parameter estimation

Problem 1

The primary objective of this problem is to verify the reliability of point estimates and confidence intervals for the parameter $\theta = 1/\lambda$ of an exponential distribution. We will have to verify that the interval estimates produced by the known rules indeed contain the parameter with probability equal to the confidence level.

### Constants

```{r}
theta <- id/10
M <- 10000
n <- 100
alphas <- c(0.1, 0.05, 0.01)
alpha <- 0.1
```

### Basic statistics

```{r}
# theta = 1 / lambda, so => lambda = 1 / theta
lambda <- 1 / theta

X <- matrix(rexp(n * M, rate = lambda), nrow = M)

# Calculate Statistics for each row
sample_means <- rowMeans(X) # Sample Mean
sample_sds <- apply(X, 1, sd) # Sample Standard Deviation
```

## Finding the confidence intervals

## Method 1

**Goal:** Verify confidence intervals (CI) for the parameter $\theta = 1/\lambda$ of an exponential distribution using the exact distribution of the statistic $2\lambda n \overline{X}$.

We are given $X_1, \dots, X_n \sim \mathcal{E}(\lambda)$. We know that the sum of independent exponential random variables follows a Gamma distribution: $$\sum_{i=1}^n X_i \sim \text{Gamma}(n, \lambda)$$ Since $\overline{X} = \frac{1}{n}\sum X_i$, then $n\overline{X} \sim \text{Gamma}(n, \lambda)$.

We use the scaling property of the Gamma distribution: if $Y \sim \text{Gamma}(n, \lambda)$, then $cY \sim \text{Gamma}(n, \lambda/c)$. However, a more direct relationship to the Chi-squared distribution is standard in probability theory:

1\. $2\lambda X_i \sim \mathcal{E}(1/2)$, which is equivalent to $\chi^2_2$ (Chi-squared with 2 degrees of freedom).

2\. The sum of independent $\chi^2$ variables is also $\chi^2$, with degrees of freedom summing up.

3\. Therefore, $\sum_{i=1}^n 2\lambda X_i = 2\lambda \sum X_i = 2\lambda n \overline{X} \sim \chi^2_{2n}$.

```{r}
statistic <- 2 * lambda * n * sample_means

hist(statistic, breaks = 50, freq = FALSE, 
     main = paste("Distribution of 2*lambda*n*X_bar (n =", n, ")"),
     xlab = "Value", col = "lightblue", border = "white")

curve(dchisq(x, df = 2 * n), from = min(statistic), to = max(statistic), 
      add = TRUE, col = "red", lwd = 2)
legend("topright", legend = c("Simulated", "Theoretical Chi-Sq"), 
       col = c("lightblue", "red"), lwd = c(10, 2))
```

#### Derivation of the Confidence Interval

To construct a CI with level $1-\alpha$, we use the pivot $W = 2\lambda n \overline{X}$: $$P(\chi^2_{2n, \alpha/2} \le 2\lambda n \overline{X} \le \chi^2_{2n, 1-\alpha/2}) = 1 - \alpha$$ Substituting $\lambda = 1/\theta$: $$\chi^2_{2n, \alpha/2} \le \frac{2n\overline{X}}{\theta} \le \chi^2_{2n, 1-\alpha/2}$$ Inverting for $\theta$ : $$\frac{2n\overline{X}}{\chi^2_{2n, 1-\alpha/2}} \le \theta \le \frac{2n\overline{X}}{\chi^2_{2n, \alpha/2}}$$

```{r}
# Critical values (Quantiles)
# Lower tail (alpha/2) and Upper tail (1 - alpha/2)
chi_lower_q <- qchisq(alpha / 2, df = 2 * n)
chi_upper_q <- qchisq(1 - alpha / 2, df = 2 * n)

# Calculate Bounds for each simulation
# Lower Bound of CI
ci_lower <- (2 * n * sample_means) / chi_upper_q
# Upper Bound of CI
ci_upper <- (2 * n * sample_means) / chi_lower_q

# Check Coverage: Does the interval contain true theta?
is_covered <- (theta >= ci_lower) & (theta <= ci_upper)

# Statistics
coverage_prob <- mean(is_covered)
avg_length <- mean(ci_upper - ci_lower)

# Output Results
cat("Method 1 (Exact Chi-Square) Results:\n")
cat("Target Confidence Level:", 1 - alpha, "\n")
cat("Observed Coverage Probability:", coverage_prob, "\n")
cat("Average Interval Length:", avg_length, "\n")
```

## Method 2

**Goal:** Construct a confidence interval using the Central Limit Theorem (CLT), assuming the population variance is known.

According to the Central Limit Theorem, for a large sample size $n$, the sample mean $\overline{X}$ of i.i.d. random variables with mean $\mu$ and variance $\sigma^2$ follows an approximate normal distribution: $$\overline{X} \sim \mathcal{N}\left(\mu, \frac{\sigma^2}{n}\right)$$

For the Exponential distribution $\mathcal{E}(\lambda)$ where parameter $\theta = 1/\lambda$: \* Mean $\mu = \theta$ \* Variance $\sigma^2 = \theta^2$

Thus, the standardized Z-statistic is: $$Z = \frac{\overline{X} - \theta}{\sigma/\sqrt{n}} = \frac{\overline{X} - \theta}{\theta/\sqrt{n}} \approx \mathcal{N}(0, 1)$$

```{r}
# Calculate the Z-statistic using the TRUE standard deviation (theta)
# Z = (X_bar - mu) / (sigma / sqrt(n))
z_statistic <- (sample_means - theta) / (theta / sqrt(n))

# Plot histogram vs Standard Normal PDF
hist(z_statistic, breaks = 60, freq = FALSE, 
     main = paste("Distribution of Z-statistic (n =", n, ")"),
     xlab = "Z value", col = "lightgreen", border = "white")

# Overlay Standard Normal density (Mean=0, SD=1)
curve(dnorm(x, mean = 0, sd = 1), 
      from = min(z_statistic), to = max(z_statistic), 
      add = TRUE, col = "darkblue", lwd = 2)

legend("topright", legend = c("Simulated Z", "Standard Normal"), 
       col = c("lightgreen", "darkblue"), lwd = c(10, 2))
```

#### Derivation of the Confidence Interval

We seek an interval such that $P(|\theta - \overline{X}| \le \text{margin}) = 1 - \alpha$. Using the Z-statistic: $$P\left( -z_{1-\alpha/2} \le \frac{\overline{X} - \theta}{\theta/\sqrt{n}} \le z_{1-\alpha/2} \right) \approx 1 - \alpha$$

Rearranging this inequality to isolate $\theta$ *in the center* relative to $\overline{X}$ gives the interval: $$\overline{X} - z_{1-\alpha/2}\frac{\theta}{\sqrt{n}} \le \theta \le \overline{X} + z_{1-\alpha/2}\frac{\theta}{\sqrt{n}}$$

```{r}
# Calculate the critical Z value (quantile)
z_crit <- qnorm(1 - alpha / 2)

# Calculate the "Known Variance" Margin of Error
# We use the true theta here
margin_error <- z_crit * (theta / sqrt(n))

# Construct Intervals
ci_lower <- sample_means - margin_error
ci_upper <- sample_means + margin_error

# Check Coverage
is_covered <- (theta >= ci_lower) & (theta <= ci_upper)

# Statistics
coverage_prob <- mean(is_covered)
avg_length <- mean(ci_upper - ci_lower)

# Output Results
cat("Method 2 (Normal Approx with Known Variance) Results:\n")
cat("Target Confidence Level:", 1 - alpha, "\n")
cat("Observed Coverage Probability:", coverage_prob, "\n")
cat("Average Interval Length:", avg_length, "\n")
```

## Method 3

**Goal:** Construct a confidence interval by solving the double inequality $|\theta - \overline{X}| [cite_start]\le z_{\beta}\theta/\sqrt{n}$ for the unknown parameter $\theta$.

```{r}
# Method 3 still relies on the Z-statistic being Standard Normal
# to justify the choice of z_beta.
z_statistic <- (sample_means - theta) / (theta / sqrt(n))

hist(z_statistic, breaks = 60, freq = FALSE, 
     main = paste("Underlying Z-Statistic (n =", n, ")"),
     xlab = "Z value", col = "plum", border = "white")

curve(dnorm(x, mean = 0, sd = 1), 
      from = min(z_statistic), to = max(z_statistic), 
      add = TRUE, col = "darkblue", lwd = 2)

legend("topright", legend = c("Simulated Z", "Standard Normal"), 
       col = c("plum", "darkblue"), lwd = c(10, 2))
```

#### Derivation of the Confidence Interval

In Method 2, we used the inequality $|\overline{X} - \theta| \le z \frac{\theta}{\sqrt{n}}$. However, using $\theta$ in the margin of error is impractical because $\theta$ is unknown. Method 3 fixes this by algebraically isolating $\theta$.

Let $k = \frac{z_{\beta}}{\sqrt{n}}$. The inequality is: $$|\overline{X} - \theta| \le k\theta$$

We can rewrite this as: $$-k\theta \le \overline{X} - \theta \le k\theta$$

Add $\theta$ to all sides: $$\theta - k\theta \le \overline{X} \le \theta + k\theta$$ $$\theta(1 - k) \le \overline{X} \le \theta(1 + k)$$

This gives us two separate inequalities to solve for $\theta$:

1.  **Upper Bound:** From $\overline{X} \le \theta(1 + k)$, we get: $$\theta \ge \frac{\overline{X}}{1 + k}$$

2.  **Lower Bound:** From $\theta(1 - k) \le \overline{X}$, assuming $k < 1$ (which is true for large $n$): $$\theta \le \frac{\overline{X}}{1 - k}$$

Thus, the confidence interval is: $$\left[ \frac{\overline{X}}{1 + \frac{z_{\beta}}{\sqrt{n}}}, \quad \frac{\overline{X}}{1 - \frac{z_{\beta}}{\sqrt{n}}} \right]$$

```{r}
# Critical Z value
z_crit <- qnorm(1 - alpha / 2)
k <- z_crit / sqrt(n)

# Construct Intervals using the derived formula
# Lower Limit: X_bar / (1 + k)
ci_lower <- sample_means / (1 + k)

# Upper Limit: X_bar / (1 - k)
ci_upper <- sample_means / (1 - k)

# Check Coverage
is_covered <- (theta >= ci_lower) & (theta <= ci_upper)

# Statistics
coverage_prob <- mean(is_covered)
avg_length <- mean(ci_upper - ci_lower)

# Output Results
cat("Method 3 (Solved Inequality) Results:\n")
cat("Target Confidence Level:", 1 - alpha, "\n")
cat("Observed Coverage Probability:", coverage_prob, "\n")
cat("Average Interval Length:", avg_length, "\n")
```

## Method 4

**Goal:** Construct a confidence interval using the sample standard deviation ($S$) to estimate the unknown population standard deviation ($\sigma$).

In Method 2, we assumed we knew the population variance ($\sigma^2 = \theta^2$). In practice, we rarely know the true variance. Instead, we estimate $\sigma$ using the **sample standard deviation** $S$: $$S = \sqrt{\frac{1}{n-1}\sum_{i=1}^n (X_i - \overline{X})^2}$$

When we replace the true $\sigma$ with the estimated $S$ in the standardization formula, the resulting statistic follows a **Student's t-distribution** with $n-1$ degrees of freedom (assuming the underlying data is normal, or appealing to the CLT for large samples): $$T = \frac{\overline{X} - \theta}{S/\sqrt{n}} \sim t_{n-1}$$

```{r}
# Calculate T-statistic using the SAMPLE standard deviation
# T = (X_bar - theta) / (S / sqrt(n))
t_statistic <- (sample_means - theta) / (sample_sds / sqrt(n))

# Plot histogram vs Theoretical t-distribution
hist(t_statistic, breaks = 60, freq = FALSE, 
     main = paste("Distribution of T-statistic (n =", n, ")"),
     xlab = "T value", col = "orange", border = "white")

# Overlay Student's t density (df = n - 1)
curve(dt(x, df = n - 1), 
      from = min(t_statistic), to = max(t_statistic), 
      add = TRUE, col = "black", lwd = 2)

legend("topright", legend = c("Simulated T", "Theoretical t_n-1"), 
       col = c("orange", "black"), lwd = c(10, 2))
```

#### Derivation of the Confidence Interval

The confidence interval is constructed as: $$\overline{X} - t_{n-1, 1-\alpha/2} \frac{S}{\sqrt{n}} \le \theta \le \overline{X} + t_{n-1, 1-\alpha/2} \frac{S}{\sqrt{n}}$$

This is the most "universal" approach because it does not require knowing $\theta$ or $\sigma$ beforehand to calculate the margin of error.

```{r}
# Critical t value (Quantile)
t_crit <- qt(1 - alpha/2, df = n - 1)

# Calculate Margin of Error using Sample SD
margin_error <- t_crit * (sample_sds / sqrt(n))

# Construct Intervals
ci_lower <- sample_means - margin_error
ci_upper <- sample_means + margin_error

# Check Coverage
is_covered <- (theta >= ci_lower) & (theta <= ci_upper)

# Statistics
coverage_prob <- mean(is_covered)
avg_length <- mean(ci_upper - ci_lower)

# Output Results
cat("Method 4 (Student's t) Results:\n")
cat("Target Confidence Level:", 1 - alpha, "\n")
cat("Observed Coverage Probability:", coverage_prob, "\n")
cat("Average Interval Length:", avg_length, "\n")
```

## Conclusions

For this specific problem (Exponential Distribution), **Method 1 (Exact Chi-Squared)** is the best method.

It is based on the exact distribution of the data, not an approximation. It works correctly even for small sample sizes ($n < 30$) where the Central Limit Theorem might not fully apply yet. Also, the Exponential distribution is skewed. The Chi-squared interval is naturally asymmetric, which better fits the data structure compared to the symmetric intervals produced by the Normal/Student approximations.

\-

\-

\-

\-

\-

## Tests summary

-   **Method 1 (Exact Chi-Squared):** This method uses the exact distribution of the sum of exponential variables. It does not rely on approximations. The intervals are asymmetric, reflecting the skewness of the underlying exponential distribution.
-   **Method 2 (Normal Approx, Known Variance):** This produced consistent intervals, but it is **impractical**. It relies on knowing the true parameter $\theta$ to calculate the standard error. In a real-world scenario, if we knew $\theta$ to calculate the interval width, we wouldn't need to estimate it.
-   **Method 3 (Solved Inequality):** This provides a valid asymptotic interval without "cheating" (it doesn't use the true $\theta$). However, the algebra is more complex, and it still relies on the Central Limit Theorem (CLT).
-   **Method 4 (Student's t):** This is the standard "universal" method. It uses the sample standard deviation ($S$) to estimate variability. It works well for large $n$ but assumes the sampling distribution of the mean is Normal (CLT).

## Analysis of Simulation Parameters

### Effect of Sample Size ($n$)

-   **Precision:** As $n$ increases, the Confidence Interval becomes **narrower**. This is because the width of the interval is proportional to $1/\sqrt{n}$. More data leads to a more precise estimate.
-   **Approximation Quality:** For Methods 2, 3, and 4, increasing $n$ improves the validity of the interval. Since these rely on the Central Limit Theorem, a larger $n$ makes the distribution of the sample mean closer to a Normal distribution, making the "Observed Coverage" closer to the theoretical confidence level.

### Effect of Repetitions ($m$)

-   **Stability:** Increasing $m$ does **not** change the interval length or the theoretical accuracy. Instead, it reduces simulation noise.
-   **Reliability:** A larger $m$ (e.g., 10,000 vs 1,000) makes our "Observed Coverage Probability" result more reliable. If we ran the code with $m=10$, the result might be 80% or 100% just by luck. With $m=10,000$, the result stabilizes very close to $0.95$.

## Problem 2

Task: Repeat the analysis of confidence intervals for a Poisson distribution $\mathcal{P}(\theta)$.

We need to verify that the confidence intervals constructed contain the parameter $\theta$ with the prescribed probability. We will analyze this using the three methods from Problem 1 (but excluding the Chi-Squared method which is only for Exponential)

### Data Generation

For the Poisson distribution $\mathcal{P}(\theta)$: Mean: $E[X] = \theta$ Variance: $Var(X) = \theta$

```{r}
# parameters
theta <- id / 10  # 3.2
lambda <- theta
n <- 100
M <- 10000
alpha <- 0.1

X_pois <- matrix(rpois(n * M, lambda = lambda), nrow = M)

pois_means <- rowMeans(X_pois)
pois_sds <- apply(X_pois, 1, sd)
```

## Method 1: Normal Approximation (Known Variance)

Goal: Construct CIs using the Normal approximation, assuming we know the true variance.

By CLT, $\frac{\overline{X} - \theta}{\sqrt{\theta/n}} \approx \mathcal{N}(0,1)$

```{r}
# Z-statistic
z_stat_pois <- (pois_means - theta) / (sqrt(theta) / sqrt(n))

# plotting
hist(z_stat_pois, breaks = 50, freq = FALSE, main = "Z-statistic (Poisson)", col = "lightgreen")
curve(dnorm(x), add = TRUE, col = "blue", lwd = 2)
```

Confidence Interval:

$$\overline{X} \pm z_{1-\alpha/2} \sqrt{\frac{\theta}{n}}$$

```{r}
z_crit <- qnorm(1 - alpha/2)
margin <- z_crit * sqrt(theta / n)

ci_lower <- pois_means - margin
ci_upper <- pois_means + margin

cat("Method 1 (Poisson - Known Variance):\n")
cat("Coverage:", mean(ci_lower <= theta & theta <= ci_upper), "\n")
cat("Avg Length:", mean(ci_upper - ci_lower), "\n")

```

## Method 2: Solving the Inequality (Score Interval)

Goal: Construct CIs without using the true $\theta$ in the margin of error, by solving the inequality for $\theta$.

We start with: $$ \left| \frac{\overline{X} - \theta}{\sqrt{\theta/n}} \right| \le z $$ Squaring both sides: $$ \frac{(\overline{X} - \theta)^2}{\theta/n} \le z^2 \implies (\overline{X} - \theta)^2 \le \frac{z^2}{n} \theta $$ Expanding the square: $$ \overline{X}^2 - 2\overline{X}\theta + \theta^2 \le \frac{z^2}{n} \theta $$ Rearranging into a standard quadratic form $A\theta^2 + B\theta + C \le 0$: $$ \theta^2 - \left(2\overline{X} + \frac{z^2}{n}\right)\theta + \overline{X}^2 \le 0 $$

The roots of this quadratic give the CI endpoints. Using the quadratic formula: $$ \theta_{1,2} = \frac{-B \pm \sqrt{B^2 - 4AC}}{2A} $$ Where $A=1$, $B = -(2\overline{X} + z^2/n)$, $C = \overline{X}^2$.

```{r}
A <- 1
B <- -(2 * pois_means + z_crit^2 / n)
C <- pois_means^2

discriminant <- sqrt(B^2 - 4 * A * C)

# Roots
root1 <- (-B - discriminant) / (2 * A)
root2 <- (-B + discriminant) / (2 * A)

ci_lower <- root1
ci_upper <- root2

cat("Method 2 (Poisson - Solved Quadratic):\n")
cat("Coverage:", mean(ci_lower <= theta & theta <= ci_upper), "\n")
cat("Avg Length:", mean(ci_upper - ci_lower), "\n")

```

## Method 3: Student's t-distribution

Goal: Estimate the standard error using the sample standard deviation $S$.

Since $Var(X) = \theta$, we could estimate variance with $\overline{X}$, but the standard "universal" approach uses the sample variance $S^2$: $$ \frac{\overline{X} - \theta}{S/\sqrt{n}} \sim t_{n-1} $$

```{r}
t_stat_pois <- (pois_means - theta) / (pois_sds / sqrt(n))

# Plot
hist(t_stat_pois, breaks = 50, freq = FALSE, main = "T-statistic (Poisson)", col = "orange")
curve(dt(x, df=n-1), add = TRUE, col = "black", lwd = 2)
```

Confidence Interval: $$ \overline{X} \pm t_{n-1, 1-\alpha/2} \frac{S}{\sqrt{n}} $$

```{r}
t_crit <- qt(1 - alpha/2, df = n - 1)
margin <- t_crit * (pois_sds / sqrt(n))

ci_lower <- pois_means - margin
ci_upper <- pois_means + margin

cat("Method 3 (Poisson - Student's t):\n")
cat("Coverage:", mean(ci_lower <= theta & theta <= ci_upper), "\n")
cat("Avg Length:", mean(ci_upper - ci_lower), "\n")
```

## Conclusion for Problem 2

Comparison: All three methods provide good coverage (close to the target $1-\alpha$).

Method 1 is the narrowest but invalid in practice (requires knowing $\theta$).

Method 2 (Solving the quadratic) is mathematically elegant and valid. It accounts for the fact that the variance changes with the mean. It produces slightly asymmetric intervals which is ok for Poisson (which is skewed for small $\theta$).

Method 3 is the easiest to apply and works well for large $n$, but technically assumes normality of the data more strongly.

Part II: Unbiasedness of Estimators

## **Problem 3**

In this task, you need to analyze the estimators of sample variance and their properties: we’ll prove the unbiasedness of variance estimator theoretically and check it on practice!

Example 2. Here is code to create a dataset (with known population variance; for simplicity we simulate the normal distribution)

```{r}
set.seed(42)
n <- 100
mu <- 10
sigma_squared <- 4
sigma <- sqrt(sigma_squared)
dataset <- rnorm(n, mean = mu, sd = sigma)
head(dataset)
## [1] 12.741917 8.870604 10.726257 11.265725 10.808537 9.787751
cat("Population Mean (mu):", mu, "\n")
## Population Mean (mu): 10
cat("Population Variance (sigma_squared):", sigma_squared, "\n")
## Population Variance (sigma_squared): 4
sample_mean <- mean(dataset)
sample_variance <- var(dataset)
cat("Sample Mean:", sample_mean, "\n")
## Sample Mean: 10.06503
cat("Sample Variance:", sample_variance, "\n")
## Sample Variance: 4.337697

```

There are two common estimators of sample variance:

$$
\sigma_n^2 = \frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2
$$

$$
\sigma_{n-1}^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2
$$

Task:

(a) **write the code to find the variance for the dataset;**

    ```{r}
    sigma_n_squared <- sum((dataset - mean(dataset))^2) / n

    sigma_n_minus_1_squared <- sum((dataset - mean(dataset))^2) / (n - 1)

    cat("σ²ₙ (biased):", sigma_n_squared, "\n")
    cat("σ²ₙ₋₁ (unbiased):", sigma_n_minus_1_squared, "\n")
    ```

<!-- -->

(b) **find** $σ^2_n$ **and** $σ_{n-1}^2$ **for n = 10, n = 50, n = 100, n = 1000;**

    ```{r}
    n_values <- c(10, 50, 100, 1000)
    results <- data.frame(
      n = n_values,
      sigma_n_squared = NA,
      sigma_n_minus_1_squared = NA
    )

    for (i in 1:length(n_values)) {
      n <- n_values[i]
      
      dataset <- rnorm(n, mean = mu, sd = sigma)
      
      results$sigma_n_squared[i] <- sum((dataset - mean(dataset))^2) / n
      
      results$sigma_n_minus_1_squared[i] <- sum((dataset - mean(dataset))^2) / (n - 1)
    }

    print(results)
    ```

<!-- -->

(c) **find the biases** $Bias(σ_{n}^2)$ **=** $E(σ_{n}^2)−σ^2$ **and** $Bias(σ_{n−1}^2) = E(σ_{n−1}^2)−σ^2$**;**

    ```{r}
    n_simulations <- 10000

    estimate_bias <- function(n, n_sims, mu, sigma) {
      sigma_n_vec <- numeric(n_sims)
      sigma_n_minus_1_vec <- numeric(n_sims)
      
      for (i in 1:n_sims) {
        data <- rnorm(n, mean = mu, sd = sigma)
        mean_data <- mean(data)
        
        sigma_n_vec[i] <- sum((data - mean_data)^2) / n
        sigma_n_minus_1_vec[i] <- sum((data - mean_data)^2) / (n - 1)
      }
      

      
      #expected values
      E_sigma_n <- mean(sigma_n_vec)
      E_sigma_n_minus_1 <- mean(sigma_n_minus_1_vec)
      
      #biases
      bias_n <- E_sigma_n - sigma_squared
      bias_n_minus_1 <- E_sigma_n_minus_1 - sigma_squared
      
      return(c(E_sigma_n, E_sigma_n_minus_1, bias_n, bias_n_minus_1))
    }

    #all sample sizes
    results <- t(sapply(n_values, estimate_bias, 
                        n_sims = n_simulations, mu = mu, sigma = sigma))

    bias_table <- data.frame(
      n = n_values,
      E_sigma_n = results[, 1],
      E_sigma_n_minus_1 = results[, 2],
      Bias_sigma_n = results[, 3],
      Bias_sigma_n_minus_1 = results[, 4]
    )

    print(bias_table)

    ```

<!-- -->

(d) **comment on the results for the different values of n;**

σ²ₙ is biased and underestimates the true variance, especially for small samples. σ²ₙ₋₁ is unbiased and accurate for all sample sizes(always is around 0). As n gets larger, both estimators give similar results.

(e) **derive analytically the expected value of each estimator E(σ2n) and E(σ2n−1);**

By definition, which is given above, we have: $$
\sigma_n^2 = \frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2
$$

Now we should plug it in under the expectation brackets and use linearity of expectation: $$
E(\sigma_n^2) = E\left(\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2\right) = \frac{1}{n}E\left(\sum_{i=1}^{n}(X_i - \bar{X})^2\right)
$$

Sum of squared deviations could be rewritten like this: $$
\sum_{i=1}^{n}(X_i - \bar{X})^2 = \sum_{i=1}^{n}(X_i - \mu + \mu - \bar{X})^2
$$

$$
= \sum_{i=1}^{n}[(X_i - \mu) - (\bar{X} - \mu)]^2
$$

$$
= \sum_{i=1}^{n}(X_i - \mu)^2 - 2(\bar{X} - \mu)\sum_{i=1}^{n}(X_i - \mu) + n(\bar{X} - \mu)^2
$$

Since $\sum_{i=1}^{n}(X_i - \mu) = n(\bar{X} - \mu)$: $$
= \sum_{i=1}^{n}(X_i - \mu)^2 - 2n(\bar{X} - \mu)^2 + n(\bar{X} - \mu)^2
$$

$$
= \sum_{i=1}^{n}(X_i - \mu)^2 - n(\bar{X} - \mu)^2
$$

Taking expectations: $$
E\left(\sum_{i=1}^{n}(X_i - \bar{X})^2\right) = E\left(\sum_{i=1}^{n}(X_i - \mu)^2\right) - nE((\bar{X} - \mu)^2)
$$

Since $E[(X_i - \mu)^2] = \sigma^2$ and $E[(\bar{X} - \mu)^2] = \text{Var}(\bar{X}) = \frac{\sigma^2}{n}$: $$
= n\sigma^2 - n \cdot \frac{\sigma^2}{n} = n\sigma^2 - \sigma^2 = (n-1)\sigma^2
$$ $$
E(\sigma_n^2) = \frac{1}{n}(n-1)\sigma^2 = \frac{n-1}{n}\sigma^2
$$Then: $$
\sigma_{n-1}^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2
$$

Taking the expected value: $$
E(\sigma_{n-1}^2) = \frac{1}{n-1}E\left(\sum_{i=1}^{n}(X_i - \bar{X})^2\right)
$$

Using the result from above: $$
E(\sigma_{n-1}^2) = \frac{1}{n-1}(n-1)\sigma^2 = \sigma^2
$$

Results:

$$
E(\sigma_n^2) = \frac{n-1}{n}\sigma^2 \quad \text{;} \quad E(\sigma_{n-1}^2) = \sigma^2
$$

(f) **using the expected values found above, show mathematically what of the above two estimators are**

unbiased;

An estimator is unbiased if its expected value equals the true parameter.

From part (e), we derived: $$E(\sigma_n^2) = \frac{n-1}{n}\sigma^2 \quad \text{and} \quad E(\sigma_{n-1}^2) = \sigma^2$$

We need to check if $E(\sigma_n^2) = \sigma^2$: $$E(\sigma_n^2) = \frac{n-1}{n}\sigma^2 \neq \sigma^2$$

Since $\frac{n-1}{n} < 1$ for all $n > 1$, we have: $$E(\sigma_n^2) < \sigma^2$$

Hence, $\sigma_n^2$ is biased (it underestimates the true variance).

Now we need to check if $E(\sigma_{n-1}^2) = \sigma^2$: $$E(\sigma_{n-1}^2) = \sigma^2$$

This equality holds exactly!

Therefore, $\sigma_{n-1}^2$ is unbiased

Conclusion\
$$\sigma_{n-1}^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2 \text{ is the unbiased estimator}$$

(g) **comment on the results behind theoretical and practical tasks.**

The theoretical derivations in parts (e) and (f) are fully confirmed by the simulation results in part (c):

**Theoretical predictions:** - E(σ²ₙ) = [(n-1)/n]σ² shows σ²ₙ is biased (take a look at the factor (n-1)/n)) - E(σ²ₙ₋₁) = σ² shows σ²ₙ₋₁ is unbiased

**Practical confirmation:** -

Comparing theoretical **vs** observed biases from the table FOR SIGMA_N:

n=10: theoretical = -0.4, observed = -0.372853482

n=50: theoretical = -0.08, observed = -0.084381877

n=100: theoretical = -0.04, observed = -0.031401389

n=1000: theoretical = -0.004, observed = -0.002798725

It is noticable that as n enlarges, the bias converges to 0, which shows that it might be not a good source of estimation for small sample sizes.

However, comparing theoretical **vs** observed biases from the table FOR SIGMA_N_MINUS_1:

n=10: theoretical = 0, observed = 0.030162798

n=50: theoretical = 0, observed = -0.004471303

n=100: theoretical =0, observed = 0.008685465

n=1000: theoretical =0, observed = 0.001202478

The simulation biases for σ²ₙ₋₁ are all very close to 0 across all sample sizes (on averege \< 0.01), confirming unbiasedness.

**SO** as n increases, the bias of σ²ₙ approaches 0, making both estimators practically equivalent for large samples.

**Key insight:** The (n-1) denominator in σ²ₙ₋₁ corrects for the fact that we're using the sample mean instead of the true population mean, which reduces the degrees of freedom by 1. This correction is essential for small samples but becomes negligible as n → ∞.

# **CONCLUSION**

In ***Problem 1***, we verified that Method 1 (Exact Chi-Squared) provides the most accurate confidence intervals for the exponential distribution parameter, achieving coverage probabilities closest to the theoretical confidence level, while other methods based on the Central Limit Theorem work well for large sample sizes but may underperform with smaller samples.

***Problem 2*** demonstrated that for Poisson distributions, all three approximation methods (Normal with known variance, solved quadratic inequality, and Student's t) produce valid confidence intervals with good coverage, though the quadratic solution method is most practical as it doesn't require knowing the true parameter.

In ***Problem 3***, we proved both theoretically and empirically that the sample variance estimator with (n-1) denominator is unbiased, while the estimator with n denominator systematically underestimates the true variance by a factor of -σ²/n, with this bias becoming negligible only for very large samples.

Overall, this lab successfully illustrated the fundamental principles of statistical estimation, demonstrating how theoretical derivations align with empirical simulations and highlighting the importance of choosing appropriate estimation methods based on the underlying distribution and sample size.
